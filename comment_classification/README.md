# Определение токсичных комментариев

## Статус проекта: завершён

## Описание проекта

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.
Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

## Навыки и инструменты

- **pandas**
- **numpy**
- **nltk**
- **matplotlib**

## Цель исследования

Определение токсичности комментариев.

## Ход исследования

Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Требуется инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

## Описание данных

Столбец text в нём содержит текст комментария, а toxic — целевой признак.

## Вывод по итогам исследования
- Исходя из проведенного анализа, можно сделать вывод, что модель LogisticRegression является наилучшей для решения поставленной задачи классификации. На обучающей выборке значение F1-меры составило 0.7668, а на тестовой выборке - 0.7678, что говорит о высокой точности модели.
- Матрица ошибок показала, что модель совершает ошибки в классификации на 1140 ложно-положительных случаях и 468 ложно-отрицательных случаях. Однако, в данном случае, ложно-положительные предсказания не являются критичными, так как в дальнейшем они будут отфильтрованы при модерации.

Таким образом, для решения поставленной задачи классификации рекомендуется использовать модель LogisticRegression."
